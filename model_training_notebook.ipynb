{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a707b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "292  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "293  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "294  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "295  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "296  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "\n",
       "     slope   ca  thal  target  \n",
       "0      3.0  0.0   6.0       0  \n",
       "1      2.0  3.0   3.0       2  \n",
       "2      2.0  2.0   7.0       1  \n",
       "3      3.0  0.0   3.0       0  \n",
       "4      1.0  0.0   3.0       0  \n",
       "..     ...  ...   ...     ...  \n",
       "292    2.0  0.0   7.0       1  \n",
       "293    2.0  0.0   7.0       1  \n",
       "294    2.0  2.0   7.0       2  \n",
       "295    2.0  1.0   7.0       3  \n",
       "296    2.0  1.0   3.0       1  \n",
       "\n",
       "[297 rows x 14 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "column_names = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\n",
    "    \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"cleveland.csv\", names=column_names)\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d24e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"].astype(int)\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\"]\n",
    "numerical = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
    "\n",
    "# Preprocessor pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", StandardScaler(), numerical),\n",
    "    (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), categorical)\n",
    "])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Feature selection (optional but improves model speed)\n",
    "selector = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "X_selected = selector.fit_transform(X_processed, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faeda21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 160, 1: 54, 2: 35, 3: 35, 4: 13})\n",
      "After SMOTE: Counter({0: 160, 2: 160, 1: 160, 3: 160, 4: 160})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Before SMOTE:\", Counter(y))\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_selected, y)\n",
    "print(\"After SMOTE:\", Counter(y_resampled))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "# Final scale for deep learning\n",
    "scaler_final = StandardScaler()\n",
    "X_train_scaled = scaler_final.fit_transform(X_train)\n",
    "X_test_scaled = scaler_final.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aec713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - accuracy: 0.2477 - loss: 2.1712 - val_accuracy: 0.2250 - val_loss: 1.7383 - learning_rate: 3.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2390 - loss: 2.1532 - val_accuracy: 0.2625 - val_loss: 1.6616 - learning_rate: 3.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2920 - loss: 1.9026 - val_accuracy: 0.2688 - val_loss: 1.5901 - learning_rate: 3.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2727 - loss: 1.8214 - val_accuracy: 0.3125 - val_loss: 1.5235 - learning_rate: 3.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3351 - loss: 1.6795 - val_accuracy: 0.3375 - val_loss: 1.4595 - learning_rate: 3.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3122 - loss: 1.6757 - val_accuracy: 0.3938 - val_loss: 1.3968 - learning_rate: 3.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3872 - loss: 1.5056 - val_accuracy: 0.4062 - val_loss: 1.3381 - learning_rate: 3.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3806 - loss: 1.4550 - val_accuracy: 0.4625 - val_loss: 1.2840 - learning_rate: 3.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4264 - loss: 1.4623 - val_accuracy: 0.5437 - val_loss: 1.2305 - learning_rate: 3.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4342 - loss: 1.4268 - val_accuracy: 0.5875 - val_loss: 1.1824 - learning_rate: 3.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4758 - loss: 1.2931 - val_accuracy: 0.6125 - val_loss: 1.1400 - learning_rate: 3.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4632 - loss: 1.2977 - val_accuracy: 0.6187 - val_loss: 1.1010 - learning_rate: 3.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5044 - loss: 1.2885 - val_accuracy: 0.6250 - val_loss: 1.0643 - learning_rate: 3.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4703 - loss: 1.3217 - val_accuracy: 0.6375 - val_loss: 1.0301 - learning_rate: 3.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4995 - loss: 1.2243 - val_accuracy: 0.6438 - val_loss: 0.9983 - learning_rate: 3.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4945 - loss: 1.2800 - val_accuracy: 0.6500 - val_loss: 0.9679 - learning_rate: 3.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5607 - loss: 1.1160 - val_accuracy: 0.6812 - val_loss: 0.9388 - learning_rate: 3.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5261 - loss: 1.1584 - val_accuracy: 0.6938 - val_loss: 0.9124 - learning_rate: 3.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5843 - loss: 1.0635 - val_accuracy: 0.6938 - val_loss: 0.8887 - learning_rate: 3.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5269 - loss: 1.1421 - val_accuracy: 0.7125 - val_loss: 0.8663 - learning_rate: 3.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5900 - loss: 1.0332 - val_accuracy: 0.7312 - val_loss: 0.8431 - learning_rate: 3.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5720 - loss: 1.0461 - val_accuracy: 0.7375 - val_loss: 0.8210 - learning_rate: 3.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6160 - loss: 0.9827 - val_accuracy: 0.7437 - val_loss: 0.8027 - learning_rate: 3.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6039 - loss: 1.0290 - val_accuracy: 0.7437 - val_loss: 0.7868 - learning_rate: 3.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6469 - loss: 0.9263 - val_accuracy: 0.7500 - val_loss: 0.7721 - learning_rate: 3.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6098 - loss: 0.9955 - val_accuracy: 0.7500 - val_loss: 0.7579 - learning_rate: 3.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6340 - loss: 0.9151 - val_accuracy: 0.7625 - val_loss: 0.7441 - learning_rate: 3.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6094 - loss: 1.0090 - val_accuracy: 0.7688 - val_loss: 0.7313 - learning_rate: 3.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6015 - loss: 0.9324 - val_accuracy: 0.7625 - val_loss: 0.7186 - learning_rate: 3.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5882 - loss: 1.0483 - val_accuracy: 0.7625 - val_loss: 0.7078 - learning_rate: 3.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6459 - loss: 0.9075 - val_accuracy: 0.7688 - val_loss: 0.6960 - learning_rate: 3.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6678 - loss: 0.8830 - val_accuracy: 0.7812 - val_loss: 0.6846 - learning_rate: 3.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6294 - loss: 0.9475 - val_accuracy: 0.7937 - val_loss: 0.6728 - learning_rate: 3.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6308 - loss: 0.9327 - val_accuracy: 0.7937 - val_loss: 0.6626 - learning_rate: 3.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6471 - loss: 0.9008 - val_accuracy: 0.7937 - val_loss: 0.6526 - learning_rate: 3.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6664 - loss: 0.8964 - val_accuracy: 0.8062 - val_loss: 0.6414 - learning_rate: 3.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6622 - loss: 0.8546 - val_accuracy: 0.8062 - val_loss: 0.6310 - learning_rate: 3.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6987 - loss: 0.7907 - val_accuracy: 0.8125 - val_loss: 0.6204 - learning_rate: 3.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6554 - loss: 0.8656 - val_accuracy: 0.8125 - val_loss: 0.6128 - learning_rate: 3.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6991 - loss: 0.7766 - val_accuracy: 0.8125 - val_loss: 0.6058 - learning_rate: 3.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7079 - loss: 0.7934 - val_accuracy: 0.8125 - val_loss: 0.5980 - learning_rate: 3.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6799 - loss: 0.8352 - val_accuracy: 0.8125 - val_loss: 0.5900 - learning_rate: 3.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6806 - loss: 0.7981 - val_accuracy: 0.8125 - val_loss: 0.5821 - learning_rate: 3.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7081 - loss: 0.8092 - val_accuracy: 0.8188 - val_loss: 0.5731 - learning_rate: 3.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6787 - loss: 0.8120 - val_accuracy: 0.8188 - val_loss: 0.5638 - learning_rate: 3.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7307 - loss: 0.7137 - val_accuracy: 0.8188 - val_loss: 0.5539 - learning_rate: 3.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6977 - loss: 0.8117 - val_accuracy: 0.8188 - val_loss: 0.5456 - learning_rate: 3.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7209 - loss: 0.7636 - val_accuracy: 0.8250 - val_loss: 0.5377 - learning_rate: 3.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7120 - loss: 0.7703 - val_accuracy: 0.8313 - val_loss: 0.5313 - learning_rate: 3.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7455 - loss: 0.6977 - val_accuracy: 0.8313 - val_loss: 0.5255 - learning_rate: 3.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7013 - loss: 0.7536 - val_accuracy: 0.8313 - val_loss: 0.5188 - learning_rate: 3.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7253 - loss: 0.7205 - val_accuracy: 0.8313 - val_loss: 0.5121 - learning_rate: 3.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7461 - loss: 0.6813 - val_accuracy: 0.8250 - val_loss: 0.5059 - learning_rate: 3.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7248 - loss: 0.6885 - val_accuracy: 0.8313 - val_loss: 0.4996 - learning_rate: 3.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7108 - loss: 0.7179 - val_accuracy: 0.8375 - val_loss: 0.4935 - learning_rate: 3.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7655 - loss: 0.6921 - val_accuracy: 0.8375 - val_loss: 0.4878 - learning_rate: 3.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7790 - loss: 0.6516 - val_accuracy: 0.8375 - val_loss: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7518 - loss: 0.6552 - val_accuracy: 0.8375 - val_loss: 0.4741 - learning_rate: 3.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7350 - loss: 0.6954 - val_accuracy: 0.8438 - val_loss: 0.4659 - learning_rate: 3.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7229 - loss: 0.7139 - val_accuracy: 0.8438 - val_loss: 0.4568 - learning_rate: 3.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7786 - loss: 0.6408 - val_accuracy: 0.8438 - val_loss: 0.4494 - learning_rate: 3.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7444 - loss: 0.6629 - val_accuracy: 0.8438 - val_loss: 0.4437 - learning_rate: 3.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7830 - loss: 0.6328 - val_accuracy: 0.8500 - val_loss: 0.4374 - learning_rate: 3.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7479 - loss: 0.6302 - val_accuracy: 0.8500 - val_loss: 0.4307 - learning_rate: 3.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7409 - loss: 0.6591 - val_accuracy: 0.8500 - val_loss: 0.4249 - learning_rate: 3.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7633 - loss: 0.6538 - val_accuracy: 0.8562 - val_loss: 0.4195 - learning_rate: 3.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8039 - loss: 0.5932 - val_accuracy: 0.8500 - val_loss: 0.4154 - learning_rate: 3.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8049 - loss: 0.6127 - val_accuracy: 0.8500 - val_loss: 0.4118 - learning_rate: 3.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7978 - loss: 0.5796 - val_accuracy: 0.8500 - val_loss: 0.4076 - learning_rate: 3.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7964 - loss: 0.6041 - val_accuracy: 0.8500 - val_loss: 0.4035 - learning_rate: 3.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8058 - loss: 0.5625 - val_accuracy: 0.8500 - val_loss: 0.4002 - learning_rate: 3.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8138 - loss: 0.5515 - val_accuracy: 0.8500 - val_loss: 0.3981 - learning_rate: 3.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8161 - loss: 0.5482 - val_accuracy: 0.8438 - val_loss: 0.3958 - learning_rate: 3.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8305 - loss: 0.5279 - val_accuracy: 0.8438 - val_loss: 0.3932 - learning_rate: 3.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8245 - loss: 0.5124 - val_accuracy: 0.8500 - val_loss: 0.3903 - learning_rate: 3.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8352 - loss: 0.4987 - val_accuracy: 0.8500 - val_loss: 0.3865 - learning_rate: 3.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8096 - loss: 0.5620 - val_accuracy: 0.8500 - val_loss: 0.3820 - learning_rate: 3.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8075 - loss: 0.5475 - val_accuracy: 0.8625 - val_loss: 0.3787 - learning_rate: 3.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8406 - loss: 0.4811 - val_accuracy: 0.8687 - val_loss: 0.3756 - learning_rate: 3.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8027 - loss: 0.5337 - val_accuracy: 0.8687 - val_loss: 0.3724 - learning_rate: 3.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8056 - loss: 0.5177 - val_accuracy: 0.8687 - val_loss: 0.3693 - learning_rate: 3.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8017 - loss: 0.5191 - val_accuracy: 0.8687 - val_loss: 0.3664 - learning_rate: 3.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7903 - loss: 0.5645 - val_accuracy: 0.8687 - val_loss: 0.3624 - learning_rate: 3.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8112 - loss: 0.4914 - val_accuracy: 0.8750 - val_loss: 0.3588 - learning_rate: 3.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8173 - loss: 0.4986 - val_accuracy: 0.8750 - val_loss: 0.3551 - learning_rate: 3.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8146 - loss: 0.5285 - val_accuracy: 0.8750 - val_loss: 0.3510 - learning_rate: 3.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8142 - loss: 0.5068 - val_accuracy: 0.8750 - val_loss: 0.3470 - learning_rate: 3.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8543 - loss: 0.4336 - val_accuracy: 0.8750 - val_loss: 0.3435 - learning_rate: 3.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8279 - loss: 0.4825 - val_accuracy: 0.8750 - val_loss: 0.3399 - learning_rate: 3.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8345 - loss: 0.4712 - val_accuracy: 0.8750 - val_loss: 0.3369 - learning_rate: 3.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8169 - loss: 0.4976 - val_accuracy: 0.8813 - val_loss: 0.3351 - learning_rate: 3.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8444 - loss: 0.4668 - val_accuracy: 0.8813 - val_loss: 0.3325 - learning_rate: 3.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8365 - loss: 0.4603 - val_accuracy: 0.8813 - val_loss: 0.3300 - learning_rate: 3.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8457 - loss: 0.4295 - val_accuracy: 0.8813 - val_loss: 0.3280 - learning_rate: 3.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8629 - loss: 0.4503 - val_accuracy: 0.8813 - val_loss: 0.3256 - learning_rate: 3.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8127 - loss: 0.4625 - val_accuracy: 0.8813 - val_loss: 0.3231 - learning_rate: 3.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8140 - loss: 0.4907 - val_accuracy: 0.8813 - val_loss: 0.3219 - learning_rate: 3.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8499 - loss: 0.4392 - val_accuracy: 0.8813 - val_loss: 0.3207 - learning_rate: 3.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8252 - loss: 0.4376 - val_accuracy: 0.8813 - val_loss: 0.3195 - learning_rate: 3.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8613 - loss: 0.3862 - val_accuracy: 0.8750 - val_loss: 0.3174 - learning_rate: 3.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8248 - loss: 0.4778 - val_accuracy: 0.8750 - val_loss: 0.3153 - learning_rate: 3.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8404 - loss: 0.4387 - val_accuracy: 0.8687 - val_loss: 0.3142 - learning_rate: 3.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8592 - loss: 0.4382 - val_accuracy: 0.8687 - val_loss: 0.3136 - learning_rate: 3.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8497 - loss: 0.4209 - val_accuracy: 0.8687 - val_loss: 0.3137 - learning_rate: 3.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8569 - loss: 0.4221 - val_accuracy: 0.8750 - val_loss: 0.3119 - learning_rate: 3.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8714 - loss: 0.3807 - val_accuracy: 0.8687 - val_loss: 0.3088 - learning_rate: 3.0000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8483 - loss: 0.4242 - val_accuracy: 0.8687 - val_loss: 0.3049 - learning_rate: 3.0000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8840 - loss: 0.3935 - val_accuracy: 0.8687 - val_loss: 0.3025 - learning_rate: 3.0000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8795 - loss: 0.3769 - val_accuracy: 0.8687 - val_loss: 0.2998 - learning_rate: 3.0000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8491 - loss: 0.3970 - val_accuracy: 0.8687 - val_loss: 0.2974 - learning_rate: 3.0000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8698 - loss: 0.4028 - val_accuracy: 0.8750 - val_loss: 0.2944 - learning_rate: 3.0000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8579 - loss: 0.4063 - val_accuracy: 0.8750 - val_loss: 0.2919 - learning_rate: 3.0000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8847 - loss: 0.3653 - val_accuracy: 0.8687 - val_loss: 0.2898 - learning_rate: 3.0000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8840 - loss: 0.3983 - val_accuracy: 0.8687 - val_loss: 0.2871 - learning_rate: 3.0000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8832 - loss: 0.3582 - val_accuracy: 0.8687 - val_loss: 0.2851 - learning_rate: 3.0000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8995 - loss: 0.3198 - val_accuracy: 0.8687 - val_loss: 0.2840 - learning_rate: 3.0000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8597 - loss: 0.3899 - val_accuracy: 0.8687 - val_loss: 0.2825 - learning_rate: 3.0000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9061 - loss: 0.3075 - val_accuracy: 0.8687 - val_loss: 0.2797 - learning_rate: 3.0000e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8867 - loss: 0.3404 - val_accuracy: 0.8687 - val_loss: 0.2780 - learning_rate: 3.0000e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8858 - loss: 0.3463 - val_accuracy: 0.8687 - val_loss: 0.2769 - learning_rate: 3.0000e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9068 - loss: 0.2989 - val_accuracy: 0.8687 - val_loss: 0.2763 - learning_rate: 3.0000e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8738 - loss: 0.3524 - val_accuracy: 0.8687 - val_loss: 0.2761 - learning_rate: 3.0000e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8755 - loss: 0.3390 - val_accuracy: 0.8750 - val_loss: 0.2760 - learning_rate: 3.0000e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8799 - loss: 0.3695 - val_accuracy: 0.8750 - val_loss: 0.2744 - learning_rate: 3.0000e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8931 - loss: 0.3243 - val_accuracy: 0.8813 - val_loss: 0.2718 - learning_rate: 3.0000e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8691 - loss: 0.3561 - val_accuracy: 0.8938 - val_loss: 0.2687 - learning_rate: 3.0000e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8711 - loss: 0.3513 - val_accuracy: 0.8938 - val_loss: 0.2661 - learning_rate: 3.0000e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8788 - loss: 0.3543 - val_accuracy: 0.8938 - val_loss: 0.2618 - learning_rate: 3.0000e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8844 - loss: 0.3522 - val_accuracy: 0.8875 - val_loss: 0.2572 - learning_rate: 3.0000e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8897 - loss: 0.3198 - val_accuracy: 0.8875 - val_loss: 0.2539 - learning_rate: 3.0000e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8970 - loss: 0.2972 - val_accuracy: 0.8875 - val_loss: 0.2525 - learning_rate: 3.0000e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8855 - loss: 0.3021 - val_accuracy: 0.8875 - val_loss: 0.2520 - learning_rate: 3.0000e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8890 - loss: 0.3425 - val_accuracy: 0.8875 - val_loss: 0.2510 - learning_rate: 3.0000e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9084 - loss: 0.3148 - val_accuracy: 0.8875 - val_loss: 0.2506 - learning_rate: 3.0000e-04\n",
      "Epoch 135/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8971 - loss: 0.2969 - val_accuracy: 0.8875 - val_loss: 0.2481 - learning_rate: 3.0000e-04\n",
      "Epoch 136/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8959 - loss: 0.3310 - val_accuracy: 0.8938 - val_loss: 0.2458 - learning_rate: 3.0000e-04\n",
      "Epoch 137/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9150 - loss: 0.3136 - val_accuracy: 0.9000 - val_loss: 0.2447 - learning_rate: 3.0000e-04\n",
      "Epoch 138/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8993 - loss: 0.3117 - val_accuracy: 0.9000 - val_loss: 0.2465 - learning_rate: 3.0000e-04\n",
      "Epoch 139/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8780 - loss: 0.3650 - val_accuracy: 0.8938 - val_loss: 0.2457 - learning_rate: 3.0000e-04\n",
      "Epoch 140/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8957 - loss: 0.3009 - val_accuracy: 0.8938 - val_loss: 0.2448 - learning_rate: 3.0000e-04\n",
      "Epoch 141/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8791 - loss: 0.3163 - val_accuracy: 0.8938 - val_loss: 0.2424 - learning_rate: 3.0000e-04\n",
      "Epoch 142/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2848 - val_accuracy: 0.8938 - val_loss: 0.2405 - learning_rate: 3.0000e-04\n",
      "Epoch 143/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8938 - loss: 0.3220 - val_accuracy: 0.9062 - val_loss: 0.2384 - learning_rate: 3.0000e-04\n",
      "Epoch 144/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8935 - loss: 0.2893 - val_accuracy: 0.9062 - val_loss: 0.2375 - learning_rate: 3.0000e-04\n",
      "Epoch 145/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8943 - loss: 0.3000 - val_accuracy: 0.9000 - val_loss: 0.2358 - learning_rate: 3.0000e-04\n",
      "Epoch 146/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9217 - loss: 0.2636 - val_accuracy: 0.8938 - val_loss: 0.2355 - learning_rate: 3.0000e-04\n",
      "Epoch 147/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8984 - loss: 0.3085 - val_accuracy: 0.9000 - val_loss: 0.2354 - learning_rate: 3.0000e-04\n",
      "Epoch 148/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8847 - loss: 0.3013 - val_accuracy: 0.9062 - val_loss: 0.2352 - learning_rate: 3.0000e-04\n",
      "Epoch 149/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9032 - loss: 0.2690 - val_accuracy: 0.9062 - val_loss: 0.2342 - learning_rate: 3.0000e-04\n",
      "Epoch 150/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8843 - loss: 0.3420 - val_accuracy: 0.9062 - val_loss: 0.2323 - learning_rate: 3.0000e-04\n",
      "Epoch 151/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9185 - loss: 0.2461 - val_accuracy: 0.9062 - val_loss: 0.2320 - learning_rate: 3.0000e-04\n",
      "Epoch 152/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8886 - loss: 0.3093 - val_accuracy: 0.9062 - val_loss: 0.2333 - learning_rate: 3.0000e-04\n",
      "Epoch 153/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9155 - loss: 0.2734 - val_accuracy: 0.9125 - val_loss: 0.2314 - learning_rate: 3.0000e-04\n",
      "Epoch 154/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9119 - loss: 0.2690 - val_accuracy: 0.9125 - val_loss: 0.2303 - learning_rate: 3.0000e-04\n",
      "Epoch 155/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9095 - loss: 0.2501 - val_accuracy: 0.9125 - val_loss: 0.2277 - learning_rate: 3.0000e-04\n",
      "Epoch 156/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8975 - loss: 0.2940 - val_accuracy: 0.9062 - val_loss: 0.2255 - learning_rate: 3.0000e-04\n",
      "Epoch 157/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9130 - loss: 0.2528 - val_accuracy: 0.9125 - val_loss: 0.2257 - learning_rate: 3.0000e-04\n",
      "Epoch 158/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9245 - loss: 0.2479 - val_accuracy: 0.9125 - val_loss: 0.2264 - learning_rate: 3.0000e-04\n",
      "Epoch 159/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9416 - loss: 0.2150 - val_accuracy: 0.9125 - val_loss: 0.2265 - learning_rate: 3.0000e-04\n",
      "Epoch 160/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9238 - loss: 0.2464 - val_accuracy: 0.9062 - val_loss: 0.2265 - learning_rate: 3.0000e-04\n",
      "Epoch 161/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9424 - loss: 0.2165 - val_accuracy: 0.9125 - val_loss: 0.2261 - learning_rate: 3.0000e-04\n",
      "Epoch 162/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9098 - loss: 0.2600 - val_accuracy: 0.9125 - val_loss: 0.2250 - learning_rate: 1.5000e-04\n",
      "Epoch 163/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9142 - loss: 0.2417 - val_accuracy: 0.9125 - val_loss: 0.2232 - learning_rate: 1.5000e-04\n",
      "Epoch 164/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9058 - loss: 0.2680 - val_accuracy: 0.9125 - val_loss: 0.2213 - learning_rate: 1.5000e-04\n",
      "Epoch 165/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9241 - loss: 0.2371 - val_accuracy: 0.9125 - val_loss: 0.2196 - learning_rate: 1.5000e-04\n",
      "Epoch 166/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9112 - loss: 0.2433 - val_accuracy: 0.9125 - val_loss: 0.2178 - learning_rate: 1.5000e-04\n",
      "Epoch 167/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8905 - loss: 0.2869 - val_accuracy: 0.9125 - val_loss: 0.2165 - learning_rate: 1.5000e-04\n",
      "Epoch 168/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9163 - loss: 0.2529 - val_accuracy: 0.9125 - val_loss: 0.2159 - learning_rate: 1.5000e-04\n",
      "Epoch 169/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9362 - loss: 0.2267 - val_accuracy: 0.9125 - val_loss: 0.2147 - learning_rate: 1.5000e-04\n",
      "Epoch 170/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8973 - loss: 0.2596 - val_accuracy: 0.9062 - val_loss: 0.2133 - learning_rate: 1.5000e-04\n",
      "Epoch 171/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9382 - loss: 0.2264 - val_accuracy: 0.9125 - val_loss: 0.2124 - learning_rate: 1.5000e-04\n",
      "Epoch 172/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9191 - loss: 0.2308 - val_accuracy: 0.9125 - val_loss: 0.2118 - learning_rate: 1.5000e-04\n",
      "Epoch 173/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9140 - loss: 0.2768 - val_accuracy: 0.9062 - val_loss: 0.2123 - learning_rate: 1.5000e-04\n",
      "Epoch 174/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9006 - loss: 0.2846 - val_accuracy: 0.9062 - val_loss: 0.2129 - learning_rate: 1.5000e-04\n",
      "Epoch 175/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9225 - loss: 0.2341 - val_accuracy: 0.9062 - val_loss: 0.2126 - learning_rate: 1.5000e-04\n",
      "Epoch 176/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9220 - loss: 0.2445 - val_accuracy: 0.9062 - val_loss: 0.2126 - learning_rate: 1.5000e-04\n",
      "Epoch 177/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9182 - loss: 0.2735 - val_accuracy: 0.9062 - val_loss: 0.2127 - learning_rate: 1.5000e-04\n",
      "Epoch 178/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8996 - loss: 0.2429 - val_accuracy: 0.9062 - val_loss: 0.2127 - learning_rate: 7.5000e-05\n",
      "Epoch 179/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9136 - loss: 0.2290 - val_accuracy: 0.9062 - val_loss: 0.2122 - learning_rate: 7.5000e-05\n",
      "Epoch 180/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9352 - loss: 0.2301 - val_accuracy: 0.9062 - val_loss: 0.2117 - learning_rate: 7.5000e-05\n",
      "Epoch 181/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9284 - loss: 0.2225 - val_accuracy: 0.9125 - val_loss: 0.2112 - learning_rate: 7.5000e-05\n",
      "Epoch 182/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9178 - loss: 0.2568 - val_accuracy: 0.9125 - val_loss: 0.2111 - learning_rate: 7.5000e-05\n",
      "Epoch 183/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9285 - loss: 0.2216 - val_accuracy: 0.9125 - val_loss: 0.2111 - learning_rate: 7.5000e-05\n",
      "Epoch 184/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9512 - loss: 0.1882 - val_accuracy: 0.9125 - val_loss: 0.2107 - learning_rate: 7.5000e-05\n",
      "Epoch 185/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9403 - loss: 0.2005 - val_accuracy: 0.9125 - val_loss: 0.2105 - learning_rate: 7.5000e-05\n",
      "Epoch 186/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9346 - loss: 0.2240 - val_accuracy: 0.9125 - val_loss: 0.2104 - learning_rate: 7.5000e-05\n",
      "Epoch 187/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9042 - loss: 0.2474 - val_accuracy: 0.9125 - val_loss: 0.2100 - learning_rate: 7.5000e-05\n",
      "Epoch 188/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9344 - loss: 0.2378 - val_accuracy: 0.9125 - val_loss: 0.2098 - learning_rate: 7.5000e-05\n",
      "Epoch 189/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9482 - loss: 0.2016 - val_accuracy: 0.9125 - val_loss: 0.2096 - learning_rate: 7.5000e-05\n",
      "Epoch 190/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9275 - loss: 0.2310 - val_accuracy: 0.9125 - val_loss: 0.2092 - learning_rate: 7.5000e-05\n",
      "Epoch 191/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9351 - loss: 0.1892 - val_accuracy: 0.9125 - val_loss: 0.2091 - learning_rate: 7.5000e-05\n",
      "Epoch 192/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9312 - loss: 0.2065 - val_accuracy: 0.9125 - val_loss: 0.2088 - learning_rate: 7.5000e-05\n",
      "Epoch 193/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9375 - loss: 0.2363 - val_accuracy: 0.9125 - val_loss: 0.2083 - learning_rate: 7.5000e-05\n",
      "Epoch 194/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2369 - val_accuracy: 0.9125 - val_loss: 0.2080 - learning_rate: 7.5000e-05\n",
      "Epoch 195/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9333 - loss: 0.2217 - val_accuracy: 0.9125 - val_loss: 0.2077 - learning_rate: 7.5000e-05\n",
      "Epoch 196/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9302 - loss: 0.2138 - val_accuracy: 0.9125 - val_loss: 0.2066 - learning_rate: 7.5000e-05\n",
      "Epoch 197/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9364 - loss: 0.2208 - val_accuracy: 0.9125 - val_loss: 0.2059 - learning_rate: 7.5000e-05\n",
      "Epoch 198/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9317 - loss: 0.1988 - val_accuracy: 0.9125 - val_loss: 0.2059 - learning_rate: 7.5000e-05\n",
      "Epoch 199/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9152 - loss: 0.2272 - val_accuracy: 0.9125 - val_loss: 0.2064 - learning_rate: 7.5000e-05\n",
      "Epoch 200/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9255 - loss: 0.2143 - val_accuracy: 0.9125 - val_loss: 0.2065 - learning_rate: 7.5000e-05\n",
      "Epoch 201/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9435 - loss: 0.2026 - val_accuracy: 0.9125 - val_loss: 0.2059 - learning_rate: 7.5000e-05\n",
      "Epoch 202/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9209 - loss: 0.2569 - val_accuracy: 0.9125 - val_loss: 0.2055 - learning_rate: 7.5000e-05\n",
      "Epoch 203/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9332 - loss: 0.2125 - val_accuracy: 0.9125 - val_loss: 0.2050 - learning_rate: 7.5000e-05\n",
      "Epoch 204/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9395 - loss: 0.2103 - val_accuracy: 0.9125 - val_loss: 0.2042 - learning_rate: 7.5000e-05\n",
      "Epoch 205/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9314 - loss: 0.1911 - val_accuracy: 0.9125 - val_loss: 0.2030 - learning_rate: 7.5000e-05\n",
      "Epoch 206/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9198 - loss: 0.2593 - val_accuracy: 0.9125 - val_loss: 0.2017 - learning_rate: 7.5000e-05\n",
      "Epoch 207/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9284 - loss: 0.2297 - val_accuracy: 0.9125 - val_loss: 0.2008 - learning_rate: 7.5000e-05\n",
      "Epoch 208/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9278 - loss: 0.2178 - val_accuracy: 0.9125 - val_loss: 0.2004 - learning_rate: 7.5000e-05\n",
      "Epoch 209/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9306 - loss: 0.1945 - val_accuracy: 0.9125 - val_loss: 0.2001 - learning_rate: 7.5000e-05\n",
      "Epoch 210/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9189 - loss: 0.2312 - val_accuracy: 0.9125 - val_loss: 0.1993 - learning_rate: 7.5000e-05\n",
      "Epoch 211/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9528 - loss: 0.1770 - val_accuracy: 0.9125 - val_loss: 0.1988 - learning_rate: 7.5000e-05\n",
      "Epoch 212/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9512 - loss: 0.1790 - val_accuracy: 0.9125 - val_loss: 0.1985 - learning_rate: 7.5000e-05\n",
      "Epoch 213/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9330 - loss: 0.1895 - val_accuracy: 0.9125 - val_loss: 0.1986 - learning_rate: 7.5000e-05\n",
      "Epoch 214/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9310 - loss: 0.2254 - val_accuracy: 0.9125 - val_loss: 0.1989 - learning_rate: 7.5000e-05\n",
      "Epoch 215/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9464 - loss: 0.1844 - val_accuracy: 0.9125 - val_loss: 0.1995 - learning_rate: 7.5000e-05\n",
      "Epoch 216/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9276 - loss: 0.2369 - val_accuracy: 0.9125 - val_loss: 0.2001 - learning_rate: 7.5000e-05\n",
      "Epoch 217/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9336 - loss: 0.2132 - val_accuracy: 0.9125 - val_loss: 0.2008 - learning_rate: 7.5000e-05\n",
      "Epoch 218/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9301 - loss: 0.1943 - val_accuracy: 0.9125 - val_loss: 0.2009 - learning_rate: 3.7500e-05\n",
      "Epoch 219/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9221 - loss: 0.2109 - val_accuracy: 0.9125 - val_loss: 0.2005 - learning_rate: 3.7500e-05\n",
      "Epoch 220/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9450 - loss: 0.1877 - val_accuracy: 0.9125 - val_loss: 0.2004 - learning_rate: 3.7500e-05\n",
      "Epoch 221/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9076 - loss: 0.2449 - val_accuracy: 0.9125 - val_loss: 0.2003 - learning_rate: 3.7500e-05\n",
      "Epoch 222/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9247 - loss: 0.2169 - val_accuracy: 0.9125 - val_loss: 0.2000 - learning_rate: 3.7500e-05\n",
      "Epoch 223/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9349 - loss: 0.2091 - val_accuracy: 0.9125 - val_loss: 0.2000 - learning_rate: 1.8750e-05\n",
      "Epoch 224/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9484 - loss: 0.1980 - val_accuracy: 0.9125 - val_loss: 0.2003 - learning_rate: 1.8750e-05\n",
      "Epoch 225/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9278 - loss: 0.2208 - val_accuracy: 0.9125 - val_loss: 0.2005 - learning_rate: 1.8750e-05\n",
      "Epoch 226/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9299 - loss: 0.2056 - val_accuracy: 0.9125 - val_loss: 0.2007 - learning_rate: 1.8750e-05\n",
      "Epoch 227/300\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9383 - loss: 0.2041 - val_accuracy: 0.9125 - val_loss: 0.2010 - learning_rate: 1.8750e-05\n",
      "Train Accuracy: 0.9891\n",
      "Test Accuracy: 0.9125\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
    "    LayerNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(5, activation=\"softmax\")  # 5-class output\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=300,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "train_loss, train_acc = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "340d8f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85        32\n",
      "           1       0.80      0.88      0.84        32\n",
      "           2       0.91      0.97      0.94        32\n",
      "           3       0.97      0.94      0.95        32\n",
      "           4       0.97      1.00      0.98        32\n",
      "\n",
      "    accuracy                           0.91       160\n",
      "   macro avg       0.92      0.91      0.91       160\n",
      "weighted avg       0.92      0.91      0.91       160\n",
      "\n",
      "Accuracy: 0.9125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d47224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heart_final_scaler.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model\n",
    "model.save(\"heart_severity_model.keras\")\n",
    "\n",
    "# Save Pipelines\n",
    "import joblib\n",
    "joblib.dump(preprocessor, \"heart_preprocessor.pkl\")\n",
    "joblib.dump(selector, \"heart_feature_selector.pkl\")\n",
    "joblib.dump(scaler_final, \"heart_final_scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c335aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('accuracy_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Loss Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_curve.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64925e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap='Blues', fmt=\".2f\")\n",
    "plt.title('Classification Report Heatmap')\n",
    "plt.savefig('classification_report_heatmap.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea8bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = history.history.get(\"learning_rate\") or []\n",
    "\n",
    "if lr_schedule:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(lr_schedule)\n",
    "    plt.title(\"Learning Rate Schedule\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"lr_schedule.png\")\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
